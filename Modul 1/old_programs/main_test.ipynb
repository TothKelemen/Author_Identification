{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f6982a",
   "metadata": {},
   "source": [
    "### A projektben használt szövegkorpusz\n",
    "\n",
    "Források\n",
    "- https://verskorpusz.elte-dh.hu/\n",
    "- https://github.com/ELTE-DH/poetry-corpus\n",
    "\n",
    "Választott szerzők\n",
    "- Ady Endre\n",
    "- Batbits Mihály\n",
    "- Karinthy Frigyes\n",
    "- Kosztolányi Dezső\n",
    "- Tóth Árpád"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857f54f",
   "metadata": {},
   "source": [
    "### 1. Alprojekt\n",
    "Adatbázis előállítása."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c756e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install pandas_read_xml\n",
    "%pip install --upgrade pip\n",
    "!pip3 install upgrade-pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d780361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import logging\n",
    "# import sys\n",
    "#print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a935e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FolderPathError(Exception):\n",
    "    def __init__(self, message = \"Egyedi hiba történt\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7bf966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_numerical_data(df, column_indices): # Egyes beolvasott adatok jellegükből adódóan csak pozitív számok lehetnek\n",
    "    \n",
    "    for column_index in column_indices:\n",
    "        column = df.iloc[:, column_index]\n",
    "        \n",
    "        for row_index, value in enumerate(column):\n",
    "            if isinstance(value, bool) or (not (isinstance(value, (int, np.int64, float, np.float64)) and value > 0)):\n",
    "                df.iloc[row_index, column_index] = np.nan\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c491b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(df, column_index): # Bővített leíró statisztika\n",
    "    \n",
    "     stat_list = [\n",
    "          df.iloc[:, column_index].mean(),\n",
    "          df.iloc[:, column_index].median(),\n",
    "          df.iloc[:, column_index].quantile(0.25),\n",
    "          df.iloc[:, column_index].quantile(0.75),\n",
    "          df.iloc[:, column_index].min(),\n",
    "          df.iloc[:, column_index].max()\n",
    "     ]              \n",
    "     stat_list.extend(\n",
    "          [\n",
    "               stat_list[5] - stat_list[4], # Terjedelem\n",
    "               (df.iloc[:, column_index] - stat_list[0]).abs().mean(), # Az átlagtól való átlagos abszolút eltérés (MAD - Mean absolute deviation)\n",
    "               (df.iloc[:, column_index] - stat_list[1]).abs().median(), # A mediántól való abszolút eltérés mediánja (MAD - Median absolute deviation)\n",
    "               df.iloc[:, column_index].std(), # Standrad szórás\n",
    "               df.iloc[:, column_index].std() / abs(stat_list[0]) # Relatív standard szórás\n",
    "          ]\n",
    "     )\n",
    "\n",
    "     stat_list = [round(item, 3) for item in stat_list]\n",
    "\n",
    "     return stat_list          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73fddedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_item(df, column_index, my_list):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for item in my_list:\n",
    "        result.append((df.iloc[:, column_index] == item).sum())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b96795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rates_simple(my_list, divisor):\n",
    "    \n",
    "    rates = []\n",
    "    \n",
    "    for item in my_list:\n",
    "        rates.append(round(item / divisor, 3))\n",
    "    \n",
    "    return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dd129f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rates_complex(my_list, my_dict, divisor): # A függvény egy listákat tartalmazó listát vár be\n",
    "    \n",
    "    rates = []\n",
    "\n",
    "    for item in my_list:\n",
    "        rates.append(round(sum([my_dict[i] for i in item]) / divisor, 3))       \n",
    "    \n",
    "    return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2c2c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rates_char(df, column_index, char_list, divisor):\n",
    "    \n",
    "    rates = []\n",
    "    \n",
    "    for char in char_list:    \n",
    "        rates.append(round(df.iloc[:, column_index].str.count(char).sum() / divisor, 3))\n",
    "    \n",
    "    return rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbffe7c",
   "metadata": {},
   "source": [
    "A vers szerzője"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f49f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author(poem_path):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        df_author = pd.read_xml(poem_path,xpath = \"//ns:titleStmt/ns:author/ns:persName\", namespaces = {\"ns\":\"http://www.tei-c.org/ns/1.0\"})\n",
    "\n",
    "        author = df_author.iloc[0, 0] + ' ' + df_author.iloc[0, 1]\n",
    "\n",
    "        author_dict = {'author': author}\n",
    "\n",
    "        return author_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "        \n",
    "        author_dict = {'author': np.nan}\n",
    "        logging.warning(f'{poem_path}: a szerző neve nem kiolvasható: {str(e)}')\n",
    "        logging.info(f'{poem_path}: ez a vers nem kerül az adatbázisba')\n",
    "        print(str(e))\n",
    "\n",
    "        return author_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96db7df1",
   "metadata": {},
   "source": [
    "A vers alapadatai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aff3be0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_features_div(poem_path):\n",
    "\n",
    "    div_keylist1 = ['title', 'nWord_title']\n",
    "    div_keylist2 = ['nStanza', 'nLine', 'nWord', 'nSyll']\n",
    "    div_keylist3 = ['rate_shortS']\n",
    "\n",
    "    try:\n",
    "\n",
    "        div_column_indices_list = [1, 2, 3, 4]\n",
    "        df_div = get_correct_numerical_data(pd.read_xml(poem_path, xpath = \"//div\"), div_column_indices_list)        \n",
    "\n",
    "        div_dict = {}\n",
    "\n",
    "        special_characters = ['!', ':', ';', '\"', '-', '.', '?', ',', '(', ')', '[', ']', '»', '«', '`']\n",
    "\n",
    "        if isinstance(df_div.iloc[0, 9], (str, int, np.int64)):\n",
    "            div_dict[div_keylist1[0]] = str(df_div.iloc[0, 9])  \n",
    "            div_dict[div_keylist1[1]] = len((''.join(char for char in div_dict['title'] if char not in special_characters)).split())          \n",
    "        else:\n",
    "            div_dict[div_keylist1[0]] = np.nan\n",
    "            div_dict[div_keylist1[1]] = np.nan\n",
    "\n",
    "        div_list = []\n",
    "\n",
    "        for i in range(1, 5):\n",
    "            if isinstance(df_div.iloc[0, i],(int, np.int64)) and df_div.iloc[0, i] > 0:\n",
    "                div_list.append(df_div.iloc[0, i])\n",
    "            else:\n",
    "                div_list.append(np.nan)\n",
    "\n",
    "        div_dict.update(dict(zip(div_keylist2, div_list)))\n",
    "        div_dict[div_keylist3[0]] = round(df_div.iloc[0, 5] / div_dict['nSyll'], 3)\n",
    "\n",
    "        return div_dict\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        div_dict = dict.fromkeys(div_keylist1 + div_keylist2 + div_keylist3, np.nan)\n",
    "        logging.warning(f'{poem_path}: A vers alapadatait nem lehet kiolvasni.')\n",
    "        print(str(e))\n",
    "\n",
    "        return div_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab74e6e7",
   "metadata": {},
   "source": [
    "A versszakok jellemzői"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b739f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_lg(poem_path):\n",
    "    \n",
    "    lg_keylist1 = ['mean_nLine_lg', 'med_nLine_lg', 'q1_nLine_lg', 'q3_nLine_lg', 'min_nLine_lg', 'max_nLine_lg', 'range_nLine_lg', 'MADmean_nLine_lg', 'MADmed_nLine_lg', 'std_nLine_lg', 'rstd_nLine_lg']\n",
    "    lg_keylist2 = ['mean_nWord_lg', 'med_nWord_lg', 'q1_nWord_lg', 'q3_nWord_lg', 'min_nWord_lg', 'max_nWord_lg', 'range_nWord_lg', 'MADmean_nWord_lg', 'MADmed_nWord_lg', 'std_nWord_lg', 'rstd_nWord_lg']\n",
    "    lg_keylist3 = ['mean_nSyll_lg', 'med_nSyll_lg', 'q1_nSyll_lg', 'q3_nSyll_lg', 'min_nSyll_lg', 'max_nSyll_lg', 'range_nSyll_lg', 'MADmean_nSyll_lg', 'MADmed_nSyll_lg', 'std_nSyll_lg', 'rstd_nSyll_lg']\n",
    "    lg_keylist4 = ['mean_nShortS_lg', 'med_nShortS_lg', 'q1_nShortS_lg', 'q3_nShortS_lg', 'min_nShortS_lg', 'max_nShortS_lg', 'range_nShortS_lg', 'MADmean_nShortS_lg', 'MADmed_nShortS_lg', 'std_nShortS_lg', 'rstd_nShortS_lg']\n",
    "    lg_keylist5 = ['mean_nLongS_lg', 'med_nLongS_lg', 'q1_nLongS_lg', 'q3_nLongS_lg', 'min_nLongS_lg', 'max_nLongS_lg', 'range_nLongS_lg', 'MADmean_nLongS_lg', 'MADmed_nLongS_lg', 'std_nLongS_lg', 'rstd_nLongS_lg']\n",
    "    lg_keylist6 = ['rhyme_abcb', 'rhyme_aba', 'rhyme_abcdb', 'rhyme_abca', 'rhyme_abb', 'rhyme_aaaa']\n",
    "\n",
    "    try:\n",
    "\n",
    "        lg_column_indices_list = [1, 2, 3, 4, 5]\n",
    "        df_lg = get_correct_numerical_data(pd.read_xml(poem_path, xpath = \"//lg\"), lg_column_indices_list)\n",
    "\n",
    "        lg_dict = {}\n",
    "        \n",
    "        keylist = [lg_keylist1, lg_keylist2, lg_keylist3, lg_keylist4, lg_keylist5]\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            lg_dict.update(dict(zip(keylist[i - 1], get_stats(df_lg, i))))\n",
    "\n",
    "        rhymelist = ['abcb', 'aba', 'abcdb', 'abca', 'abb', 'aaaa']\n",
    "        rhyme_countlist = count_item(df_lg, 6, rhymelist)\n",
    "        lg_dict.update(dict(zip(lg_keylist6, rhyme_countlist)))\n",
    "\n",
    "        return lg_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        lg_dict = dict.fromkeys(lg_keylist1 + lg_keylist2 + lg_keylist3 + lg_keylist4 + lg_keylist5 + lg_keylist6, np.nan)\n",
    "        logging.info(f'{poem_path}: A versszakok jellemzőit nem lehet kiolvasni.')\n",
    "        print(str(e))\n",
    "\n",
    "        return lg_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483d4ba",
   "metadata": {},
   "source": [
    "A verssorok jellemzői"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e216982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_l(poem_path):\n",
    "    \n",
    "    l_keylist1 = ['mean_nWord_l', 'med_nWord_l', 'q1_nWord_l', 'q3_nWord_l', 'min_nWord_l', 'max_nWord_l', 'range_nWord_l', 'MADmean_nWord_l', 'MADmed_nWord_l', 'std_nWord_l', 'rstd_nWord_l']\n",
    "    l_keylist2 = ['mean_nSyll_l', 'med_nSyll_l', 'q1_nSyll_l', 'q3_nSyll_l', 'min_nSyll_l', 'max_nSyll_l', 'range_nSyll_l', 'MADmean_nSyll_l', 'MADmed_nSyll_l', 'std_nSyll_l', 'rstd_nSyll_l']\n",
    "    l_keylist3 = ['mean_nShortS_l', 'med_nShortS_l', 'q1_nShortS_l', 'q3_nShortS_l', 'min_nShortS_l', 'max_nShortS_l', 'range_nShortS_l', 'MADmean_nShortS_l', 'MADmed_nShortS_l', 'std_nShortS_l', 'rstd_nShortS_l']\n",
    "    l_keylist4 = ['mean_nLongS_l', 'med_nLongS_l', 'q1_nLongS_l', 'q3_nLongS_l', 'min_nLongS_l', 'max_nLongS_l', 'range_nLongS_l', 'MADmean_nLongS_l', 'MADmed_nLongS_l', 'std_nLongS_l', 'rstd_nLongS_l']\n",
    "\n",
    "    try:\n",
    "\n",
    "        l_column_indices_list = [1, 2, 3, 4]\n",
    "        df_l = get_correct_numerical_data(pd.read_xml(poem_path,xpath=\"//l\"), l_column_indices_list)\n",
    "\n",
    "        l_dict={}\n",
    "        \n",
    "        keylist = [l_keylist1, l_keylist2, l_keylist3, l_keylist4]\n",
    "\n",
    "        for i in range(1, 5):\n",
    "            l_dict.update(dict(zip(keylist[i - 1],get_stats(df_l, i))))\n",
    "\n",
    "        return l_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        l_dict=dict.fromkeys(l_keylist1 + l_keylist2 + l_keylist3 + l_keylist4, np.nan)\n",
    "        logging.info(f'{poem_path}: A versszakonkénti jellemzőket nem lehet kiolvasni.')\n",
    "        print(str(e))\n",
    "\n",
    "        return l_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a4801",
   "metadata": {},
   "source": [
    "A szavak jellemzői"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "900679ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_w(poem_path):\n",
    "    \n",
    "    w_keylist1 = ['PROPN', 'NOUN', 'ADJ', 'NUM', 'PRON', 'VERB', 'ADV', 'CONJ', 'SCONJ', 'DET', 'ADP', 'INTJ', 'PART']\n",
    "    w_keylist2 = ['rate_PROPN_NOUN', 'rate_ADJ', 'rate_NOUNs', 'rate_VERB', 'rate_ADV']\n",
    "    w_keylist3 = ['rate_phontypeLow', 'rate_phontypeHigh', 'rate_phontypeMixed']\n",
    "    w_keylist4 = ['mean_lenWord', 'med_lenWord', 'q1_lenWord', 'q3_lenWord', 'min_lenWord', 'max_lenWord', 'range_lenWord', 'MADmean_lenWord', 'MADmed_lenWord', 'std_lenWord', 'rstd_lenWord']\n",
    "    w_keylist5 = ['sum_lenWord']\n",
    "    w_keylist6 = ['rate_consonant', 'rate_fFV', 'rate_FFV', 'rate_bFV', 'rate_BFV']    \n",
    "    \n",
    "    try:\n",
    "\n",
    "        div_column_indices_list = [3]\n",
    "        df_div = get_correct_numerical_data(pd.read_xml(poem_path,xpath=\"//div\"), div_column_indices_list)\n",
    "        nWord = df_div.iloc[0, 3]\n",
    "\n",
    "        df_w = pd.read_xml(poem_path,xpath=\"//w\")\n",
    "        \n",
    "        w_dict = {}\n",
    "\n",
    "        nouns_countlist = count_item(df_w, 2, w_keylist1)\n",
    "        w_dict.update(dict(zip(w_keylist1, nouns_countlist)))\n",
    "\n",
    "        nounslist = [['PROPN', 'NOUN'],['ADJ'],['PROPN', 'NOUN', 'ADJ', 'NUM', 'PRON'],['VERB'],['ADV']]\n",
    "        w_dict.update(dict(zip(w_keylist2, get_rates_complex(nounslist, w_dict, nWord))))\n",
    "\n",
    "        vowellist=['low', 'high', 'mixed']\n",
    "        vowel_countlist = count_item(df_w, 5, vowellist)\n",
    "        w_dict.update(dict(zip(w_keylist3, get_rates_simple(vowel_countlist, nWord))))\n",
    "\n",
    "        df_w['lenWord'] = df_w.iloc[:, 6].str.len()\n",
    "        w_dict.update(dict(zip(w_keylist4, get_stats(df_w, 8))))\n",
    "\n",
    "        w_dict[w_keylist5[0]] = df_w.iloc[:, 8].sum()\n",
    "        charlist=['c', 'f', 'F', 'b', 'B']\n",
    "        w_dict.update(dict(zip(w_keylist6, get_rates_char(df_w, 6, charlist, w_dict['sum_lenWord']))))\n",
    "\n",
    "        return w_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "\n",
    "        w_dict=dict.fromkeys(w_keylist1 + w_keylist2 + w_keylist3 + w_keylist4 + w_keylist5 + w_keylist6, np.nan)\n",
    "        logging.info(f'{poem_path}: A szavak jellemzőit nem lehet kiolvasni.')\n",
    "        print(str(e))\n",
    "\n",
    "        return w_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e416c5",
   "metadata": {},
   "source": [
    "Központozás a versben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b2d84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_pc(poem_path):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        df_pc = pd.read_xml(poem_path,xpath=\"//pc\")\n",
    "        \n",
    "        PUNCT = (df_pc.iloc[:, 1] == 'PUNCT').sum()\n",
    "\n",
    "        PUNCT_dict = {'PUNCT': PUNCT}\n",
    "\n",
    "        return PUNCT_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "\n",
    "        PUNCT_dict = {'PUNCT': np.nan}\n",
    "        logging.info(f'{poem_path}: Az írásjelekről nincs adat vagy a szerző nem használt központozást.')\n",
    "        print(str(e))\n",
    "\n",
    "        return PUNCT_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1988a5b",
   "metadata": {},
   "source": [
    "Rímpárok a versben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51ac3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_rhymePair(poem_path, root):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        df_rhymePair = pd.read_xml(poem_path, xpath=\"//rhymePair\")\n",
    "\n",
    "        nRhymepair = df_rhymePair.iloc[:, 2].count()\n",
    "\n",
    "        rhymePair_dict = {'nRhymepair': nRhymepair}\n",
    "\n",
    "        return rhymePair_dict\n",
    "    \n",
    "    except ValueError as e:\n",
    "\n",
    "        rhymePair_dict = {'nRhymepair': np.nan}\n",
    "        \n",
    "        if root.find(\".//rhymePairs\") is not None: \n",
    "            rhymePair_dict['nRhymepair'] = 0\n",
    "        else:                 \n",
    "            logging.info(f'{poem_path}: nem tartalmaz információt a rímpárokról.')\n",
    "            print(str(e))\n",
    "            \n",
    "        return rhymePair_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "\n",
    "        rhymePair_dict={'nRhymepair': np.nan}\n",
    "        logging.info(f'{poem_path} A rímpárokról jellemzőjét nem lehet kiolvasni.')\n",
    "        print(str(e))\n",
    "\n",
    "        return rhymePair_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794c47cf",
   "metadata": {},
   "source": [
    "Alliterációk a versben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09f1649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_alliteration(poem_path, root):\n",
    "    \n",
    "    alliteration_keylist1 = ['nAll', 'rate_clearAll']\n",
    "    alliteration_keylist2 = ['mean_lenAll', 'med_lenAll', 'q1_lenAll', 'q3_lenAll', 'min_lenAll', 'max_lenAll', 'range_lenAll', 'MADmean_lenAll', 'MADmed_lenAll', 'std_lenAll', 'rstd_lenAll']\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        df_alliteration = pd.read_xml(poem_path,xpath = \"//alliteration\")\n",
    "\n",
    "        alliteration_dict = {}          \n",
    "\n",
    "        alliteration_dict[alliteration_keylist1[0]] = df_alliteration.iloc[:, 1].count()\n",
    "\n",
    "        df_alliteration['lenAll'] = df_alliteration.iloc[:, 1].apply(len)\n",
    "        alliteration_dict[alliteration_keylist1[1]] = round((df_alliteration.iloc[:, 1].str.count('a') == df_alliteration.iloc[:, 6]).sum() / alliteration_dict['nAll'], 3)\n",
    "\n",
    "        alliteration_dict.update(dict(zip(alliteration_keylist2, get_stats(df_alliteration, 6))))\n",
    "\n",
    "        return alliteration_dict\n",
    "    \n",
    "    except ValueError as e: \n",
    "                           \n",
    "          alliteration_dict = dict.fromkeys(alliteration_keylist1 + alliteration_keylist2, np.nan)\n",
    "          \n",
    "          if root.find(\".//alliterations\") is not None: \n",
    "               alliteration_dict['nAll'] = 0\n",
    "          else:                 \n",
    "               logging.info(f'{poem_path}: Nem tartalmaz információt az alliterációkról.')\n",
    "               print(str(e))\n",
    "               \n",
    "          return alliteration_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "\n",
    "          alliteration_dict = dict.fromkeys(alliteration_keylist1 + alliteration_keylist2, np.nan)\n",
    "          logging.info(f'{poem_path}: Az alliterációk jellemzőit nem lehet kiolvasni.')\n",
    "          print(str(e))\n",
    "\n",
    "          return alliteration_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3aa9e2",
   "metadata": {},
   "source": [
    "Főprogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24d6bdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xpath does not return any nodes. Be sure row level nodes are in xpath. If document uses namespaces denoted with xmlns, be sure to define namespaces and use them in xpath.\n",
      "xpath does not return any nodes. Be sure row level nodes are in xpath. If document uses namespaces denoted with xmlns, be sure to define namespaces and use them in xpath.\n",
      "xpath does not return any nodes. Be sure row level nodes are in xpath. If document uses namespaces denoted with xmlns, be sure to define namespaces and use them in xpath.\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(filename = 'infoEvent.log', level = logging.INFO, format = '%(asctime)s - %(levelname)s - %(message)s', encoding = 'utf-8')\n",
    "\n",
    "poems_path = \"D:\\Iskolai\\Tananyagok\\Szakdolgozat\\Bsc\\Versek\"\n",
    "\n",
    "df_main = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "\n",
    "    if os.path.exists(poems_path) and os.path.isdir(poems_path):\n",
    "\n",
    "        row_index = 0\n",
    "\n",
    "        for rootfolder, folders, files in os.walk(poems_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.xml'):  # Csak az XML kiterjesztésű fájlokat vesszük figyelembe\n",
    "\n",
    "                    complete_path = os.path.join(rootfolder, file)\n",
    "                    tree = ET.parse(complete_path)\n",
    "                    root = tree.getroot()\n",
    "\n",
    "                    functionlist1 = [get_author, get_features_div, get_features_lg, get_features_l, get_features_w, get_features_pc]\n",
    "                    functionlist2 = [get_features_rhymePair, get_features_alliteration]\n",
    "\n",
    "                    main_dict = {}\n",
    "\n",
    "                    for function in functionlist1:\n",
    "                        main_dict.update(function(complete_path))\n",
    "\n",
    "                    for function in functionlist2:\n",
    "                        main_dict.update(function(complete_path,root)) \n",
    "\n",
    "                    if row_index == 0:                        \n",
    "\n",
    "                        column_names = list(main_dict.keys())\n",
    "                        label_list = ['class_label', 'nan_count_label']\n",
    "                        column_names.extend(label_list)\n",
    "                        df_main = pd.DataFrame(columns = column_names)                   \n",
    "\n",
    "                    if pd.notna(main_dict['author']):\n",
    "\n",
    "                        for item in main_dict:    \n",
    "\n",
    "                            df_main.loc[row_index,item] = main_dict[item]\n",
    "\n",
    "                        if df_main.iloc[row_index, 0] == 'Ady Endre':\n",
    "                            df_main.loc[row_index, 'class_label'] = 1\n",
    "                        else:\n",
    "                            df_main.loc[row_index, 'class_label'] = 0   \n",
    "\n",
    "                        df_main.loc[row_index, 'nan_count_label'] = df_main.iloc[row_index].isna().sum() - 1 \n",
    "\n",
    "                        row_index += 1\n",
    "\n",
    "                    else:\n",
    "                        logging.info(f'{file}: A fájlban hiányzik a szerző neve.')                                       \n",
    "\n",
    "                else:\n",
    "                    logging.info(f'{file}: A fájl nem XML kiterjesztésű.')\n",
    "\n",
    "    else:\n",
    "        raise FolderPathError(f'{poems_path}: Az elérési útvonal nem található vagy nem egy mappa.')\n",
    "\n",
    "except FolderPathError as e:\n",
    "\n",
    "    logging.error(str(e))\n",
    "    print(str(e))\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    logging.error(f'{file}: Hiba történt.')\n",
    "    file.close()\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce88a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.to_csv('poems_data.csv', index = False)\n",
    "# df_main\n",
    "# df_main.loc[3:4, 'nAll':'nan_count_label']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
